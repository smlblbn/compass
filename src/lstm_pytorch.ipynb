{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "\n",
    "torch.manual_seed(783)\n",
    "\n",
    "x_train = Variable(torch.from_numpy(x_train_np)).float()\n",
    "y_train = Variable(torch.from_numpy(y_train_np)).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.lstm = torch.nn.LSTM(         # if use nn.RNN(), it hardly learns\n",
    "            input_size=data_width,\n",
    "            hidden_size=64,         # rnn hidden unit\n",
    "            num_layers=1,           # number of rnn layer\n",
    "            batch_first=True,       # input & output will has batch size as 1s dimension. e.g. (batch, time_step, input_size)\n",
    "        )\n",
    "\n",
    "        self.out = torch.nn.Linear(64, label_team_width)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape (batch, time_step, input_size)\n",
    "        # r_out shape (batch, time_step, output_size)\n",
    "        # h_n shape (n_layers, batch, hidden_size)\n",
    "        # h_c shape (n_layers, batch, hidden_size)\n",
    "        r_out, (h_n, h_c) = self.lstm(x, None)   # None represents zero initial hidden state\n",
    "    \n",
    "        # choose r_out at the last time step\n",
    "        out = self.out(r_out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "\n",
    "rnn = RNN()\n",
    "print(rnn)\n",
    "rnn.cuda()\n",
    "\n",
    "batch_size = 100 # time sequence\n",
    "optimizer = torch.optim.Adam(rnn.parameters())   # optimize all cnn parameters\n",
    "loss_func = torch.nn.CrossEntropyLoss()          # the target label is not one-hotted\n",
    "loss_func = loss_func.cuda()\n",
    "\n",
    "# training and testing\n",
    "for epoch in range(100):\n",
    "    for idx in range(int(6000/batch_size)):\n",
    "\n",
    "        print('idx: ', idx*batch_size)\n",
    "        x_train_ = x_train[:, idx*batch_size : (idx+1)*batch_size, :]\n",
    "        y_train_ = y_train[:, idx*batch_size : (idx+1)*batch_size, :]\n",
    "\n",
    "        x_train_batch = x_train_.cuda()\n",
    "        y_train_batch = y_train_.cuda()\n",
    "\n",
    "        y_pred_train = rnn(x_train_batch)\n",
    "        loss_train = loss_func(y_pred_train, y_train_batch.type(torch.cuda.LongTensor))\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "        loss_train.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        print(loss_train.cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.layer1 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(in_channels=1, out_channels=16, kernel_size=5, stride=1, padding=2),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.BatchNorm2d(num_features=16),\n",
    "            torch.nn.MaxPool2d(kernel_size=4, stride=2)\n",
    "        )\n",
    "        self.layer2 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(in_channels=16, out_channels=24, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.BatchNorm2d(num_features=24),\n",
    "            torch.nn.MaxPool2d(kernel_size=4, stride=2)\n",
    "        )\n",
    "        self.conv = torch.nn.Conv2d(in_channels=24, out_channels=2, kernel_size=3, stride=1, padding=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.conv(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
